# AIFlash - Baseline

[ðŸ‡¨ðŸ‡³ ä¸­æ–‡è¯´æ˜Ž (Chinese)](README_CN.md)

---

## ðŸ‡¬ðŸ‡§ English

AIFlash baseline code based on [Restormer](https://github.com/swz30/Restormer).

### ðŸŽ¯ Challenge Motivation

Despite significant advances in deep learning for image restoration, existing models still struggle to balance noise removal, detail preservation, and light/color restoration in real-world low-light portrait scenarios. **AI Flash Portrait** aims to generate natural, clean, and realistic portraits while maintaining comfortable background appearance and accurate colors.

### ðŸ† Challenge Objectives

This challenge provides a platform for industrial and academic participants to test and evaluate algorithms and models in real-world imaging scenarios. The challenge objectives include:

- Establishing a benchmark for low-light portrait restoration in real scenes, covering both objective and subjective evaluation;
- Promoting the development and practical application of highly robust algorithms;
- Encouraging solutions that excel in both portrait and overall scene quality.

---

### âš ï¸ Data Description

| Data | Resolution |
|------|------------|
| Input Image | **1K** |
| Ground Truth (GT) | **1K** |
| Submission Result | **1K** |

> **Note**: The current baseline resizes images to **768** for training. Participants can adjust the training resolution based on their GPU memory. The final inference result must be in **1K resolution**.

---


### ðŸ“¥ Dataset Download

Please download the dataset from the competition page according to different stages:

ðŸ”— **Competition Link**: [https://www.codabench.org/competitions/12885/](https://www.codabench.org/competitions/12885/)

| Stage | Dataset | Status | Description |
|-------|---------|--------|-------------|
| Stage 1 | Training Set | âœ… Available | Training images (input + GT pairs + person mask) |
| Stage 2 | Test Set A | ðŸ”’ Not Available | Test images for inference (no GT) |
| Stage 3 | Test Set B | ðŸ”’ Not Available | Test images for inference (no GT) |


#### Directory Structure

After downloading, please organize the data as follows:

```
AI_Flash-BaseLine/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ input/          # Training input images (low-light)
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ 0002.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ gt/             # Training ground truth images
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ 0002.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ mask_personmask/    # Person segmentation masks (if used)
â”‚   â”‚       â”œâ”€â”€ 0001.jpg
â”‚   â”‚       â”œâ”€â”€ 0002.jpg
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ input/          # Test input images
â”‚       â”‚   â”œâ”€â”€ 0001.jpg
â”‚       â”‚   â”œâ”€â”€ 0002.jpg
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ mask_personmask/    # Person segmentation masks (if used)
â”‚           â”œâ”€â”€ 0001.jpg
â”‚           â”œâ”€â”€ 0002.jpg
â”‚           â””â”€â”€ ...
â”œâ”€â”€ configs/
â”œâ”€â”€ basicsr/
â””â”€â”€ ...
```

---


### Environment Setup

#### 1. Create Conda Environment

```bash
conda create -n aiflash python=3.10 -y
conda activate aiflash
```

#### 2. Install PyTorch (CUDA 12.1)

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

> For other CUDA versions, please refer to [PyTorch Official Website](https://pytorch.org/get-started/locally/)

#### 3. Install Other Dependencies

```bash
pip install matplotlib scikit-learn scikit-image opencv-python yacs joblib natsort h5py tqdm
pip install einops gdown addict future lmdb "numpy<2" pyyaml requests scipy tensorboard yapf lpips
```

#### 4. Install BasicSR

```bash
cd AI_Flash-BaseLine
pip install -e .
```

---

### Training

```bash
python basicsr/train.py -opt configs/flash.yaml
```

---

### Inference

```bash
python inference.py \
    --config configs/flash.yaml \
    --weights pth/net_g_xxx.pth \
    --input_dir test/input \
    --output_dir test/output
```

#### Inference Parameters

| Parameter | Required | Description |
|-----------|----------|-------------|
| `--config` | âœ… | Path to YAML config file |
| `--weights` | âœ… | Path to model weights file |
| `--input_dir` | âœ… | Input image directory or single image |
| `--output_dir` | âŒ | Output directory, default `./results` |
| `--tile` | âŒ | Tile size for large image inference |
| `--tile_overlap` | âŒ | Tile overlap, default 32 |

---

### Acknowledgement

This code is based on [Restormer](https://github.com/swz30/Restormer).

```bibtex
@inproceedings{Zamir2021Restormer,
    title={Restormer: Efficient Transformer for High-Resolution Image Restoration}, 
    author={Syed Waqas Zamir and Aditya Arora and Salman Khan and Munawar Hayat 
            and Fahad Shahbaz Khan and Ming-Hsuan Yang},
    booktitle={CVPR},
    year={2022}
}
```
